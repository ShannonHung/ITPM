{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select: Selecting the analysis results for the technical and methodical provision.\n",
    "\n",
    "Choosing analysis outcomes for technical and systematic planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "df = pd.read_csv('../data/ds_salaries_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request: If the analysis results do not suit the intended technical and methodical provision, changes can be requested. \n",
    "\n",
    "The analysis results meet expectations, so skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select: This process aligns well with the requirement that data selected for technical and methodical provision should be appropriately prepared. If new data are introduced, they should be processed in the same manner to ensure consistency with the original model's data characteristics.\n",
    "\n",
    "We calculate the 25th, 50th, and 75th percentiles of salaries in the 'salary_in_usd' column of the DataFrame df and define four salary levels based on these percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percentiles\n",
    "def convertData(data):\n",
    "    \n",
    "    percentiles = np.percentile(df['salary_in_usd'], [25, 50, 75])  # 25th, 50th, 75th percentiles\n",
    "    print(percentiles)\n",
    "    # define the labels of saraly levels \n",
    "    labels = ['Level 1', 'Level 2', 'Level 3', 'Level 4']\n",
    "\n",
    "    # print the meaning of label \n",
    "    for i in range(len(labels)):\n",
    "        if i == 0:\n",
    "            print('Level 1: < {:.2f} USD'.format(percentiles[i]))\n",
    "        elif i == len(labels) - 1:\n",
    "            print('Level {}: > {:.2f} USD'.format(i+1, percentiles[i-1]))\n",
    "        else:\n",
    "            print('Level {}: {:.2f} ~ {:.2f} USD'.format(i+1, percentiles[i-1], percentiles[i]))\n",
    "\n",
    "\n",
    "    #  -np.inf, np.inf be the lower and upper bounds of the bins\n",
    "    # *percentiles: base on the percentiles to cut the bins and generate the salary levels for being the labels of training data\n",
    "    df['salary_level'] = pd.cut(df['salary_in_usd'], bins=[-np.inf, *percentiles, np.inf], labels=labels)\n",
    "    data = df.drop(['salary_in_usd'], axis=1) # we cannot put the label into the training data\n",
    "    print(\"\\nThe data of each salary level is balanced.\")\n",
    "    print(data['salary_level'].value_counts())\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request: If the selected data do not suit the intended technical and methodical provision, changes can be requested. \n",
    "\n",
    "The selected data suit the intended technical and methodical provision,so skip this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: During the technical and methodical provision, the applicability must be checked by \n",
    "the target group for the analysis. \n",
    "\n",
    "We check by the target group for the analysis. It check the data is balanced or not and calculate each salary level's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 95000. 135000. 175000.]\n",
      "Level 1: < 95000.00 USD\n",
      "Level 2: 95000.00 ~ 135000.00 USD\n",
      "Level 3: 135000.00 ~ 175000.00 USD\n",
      "Level 4: > 175000.00 USD\n",
      "\n",
      "The data of each salary level is balanced.\n",
      "salary_level\n",
      "Level 2    967\n",
      "Level 1    956\n",
      "Level 4    932\n",
      "Level 3    900\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>salary_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ES</td>\n",
       "      <td>100</td>\n",
       "      <td>ES</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mid-level/Intermediate</td>\n",
       "      <td>Contract</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mid-level/Intermediate</td>\n",
       "      <td>Contract</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>2020</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>2021</td>\n",
       "      <td>Mid-level/Intermediate</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>2020</td>\n",
       "      <td>Entry-level/Junior</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>2020</td>\n",
       "      <td>Entry-level/Junior</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>2021</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>IN</td>\n",
       "      <td>50</td>\n",
       "      <td>IN</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3755 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      work_year        experience_level employment_type             job_title  \\\n",
       "0          2023     Senior-level/Expert       Full-Time        Data Scientist   \n",
       "1          2023  Mid-level/Intermediate        Contract           ML Engineer   \n",
       "2          2023  Mid-level/Intermediate        Contract           ML Engineer   \n",
       "3          2023     Senior-level/Expert       Full-Time        Data Scientist   \n",
       "4          2023     Senior-level/Expert       Full-Time        Data Scientist   \n",
       "...         ...                     ...             ...                   ...   \n",
       "3750       2020     Senior-level/Expert       Full-Time        Data Scientist   \n",
       "3751       2021  Mid-level/Intermediate       Full-Time        Data Scientist   \n",
       "3752       2020      Entry-level/Junior       Full-Time        Data Scientist   \n",
       "3753       2020      Entry-level/Junior        Contract          Data Analyst   \n",
       "3754       2021     Senior-level/Expert       Full-Time  Data Science Manager   \n",
       "\n",
       "     employee_residence  remote_ratio company_location company_size  \\\n",
       "0                    ES           100               ES            L   \n",
       "1                    US           100               US            S   \n",
       "2                    US           100               US            S   \n",
       "3                    CA           100               CA            M   \n",
       "4                    CA           100               CA            M   \n",
       "...                 ...           ...              ...          ...   \n",
       "3750                 US           100               US            L   \n",
       "3751                 US           100               US            L   \n",
       "3752                 US           100               US            S   \n",
       "3753                 US           100               US            L   \n",
       "3754                 IN            50               IN            L   \n",
       "\n",
       "     salary_level  \n",
       "0         Level 1  \n",
       "1         Level 1  \n",
       "2         Level 1  \n",
       "3         Level 3  \n",
       "4         Level 2  \n",
       "...           ...  \n",
       "3750      Level 4  \n",
       "3751      Level 3  \n",
       "3752      Level 2  \n",
       "3753      Level 2  \n",
       "3754      Level 1  \n",
       "\n",
       "[3755 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = convertData(df)\n",
    "data\n",
    "# each number of salary level have approximately the same number of data which occupy 25% of the whole data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply: Identified opportunities for ensuring applicability must be considered during the technical and methodical provision.\n",
    "\n",
    "We create the function to convert the data for training and testing, ensuring applicability by turning the data into tensors and normalizing it, while considering identified opportunities during the technical and methodical provision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalaryDataset(Dataset):\n",
    "\n",
    "    # Initialization function for loading and preprocessing data\n",
    "    def __init__(self, data, train=True, transform=None):\n",
    "        # The 'train' parameter indicates whether the data is for training or testing\n",
    "        self.train = train\n",
    "\n",
    "        # Create MinMaxScaler and OneHotEncoder for data preprocessing\n",
    "        minmax_scaler = MinMaxScaler()\n",
    "        onehot_enc = OneHotEncoder()\n",
    "\n",
    "        # Split data into categorical features, numerical features, and labels\n",
    "        categorical_features = data[data.select_dtypes(include=['object']).columns]\n",
    "        numerical_features = data[data.select_dtypes(exclude=['object']).columns].drop('salary_level', axis=1)\n",
    "        label_features = data[['salary_level']]\n",
    "\n",
    "        # Normalize numerical features (MinMax normalization)\n",
    "        numerical_features_arr = minmax_scaler.fit_transform(numerical_features)\n",
    "\n",
    "        # Perform one-hot encoding on categorical features\n",
    "        categorical_features_arr = onehot_enc.fit_transform(categorical_features).toarray()\n",
    "\n",
    "        # After one-hot encoding categorical features, retrieve the encoded feature names\n",
    "        label_features = onehot_enc.fit_transform(label_features).toarray()\n",
    "\n",
    "        # Combine normalized numerical features and one-hot encoded categorical features into one dataset\n",
    "        combined_features = pd.DataFrame(data=numerical_features_arr, columns=numerical_features.columns)\n",
    "        combined_features = pd.concat([combined_features, pd.DataFrame(data=categorical_features_arr)], axis=1)\n",
    "        combined_features = pd.concat([combined_features, pd.DataFrame(data=label_features)], axis=1).reset_index(drop=True)\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        train_data, test_data = train_test_split(combined_features, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Choose the data to use based on the training or testing mode\n",
    "        if train:\n",
    "            self.data = train_data\n",
    "        else:\n",
    "            self.data = test_data\n",
    "\n",
    "    # Returns the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Function for training the neural network, returns features and labels\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve the data from the ith row in the self.data DataFrame\n",
    "        sample = self.data.iloc[idx] \n",
    "        # Convert a data structure into a PyTorch tensor and specify the tensor's data type as float\n",
    "        features = torch.FloatTensor(sample[:-4])\n",
    "        label = torch.FloatTensor(sample[-4:])\n",
    "        return features, label\n",
    "\n",
    "    # Returns the entire dataset as a DataFrame\n",
    "    def getData(self):\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7. Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: During the technical and methodical provision, technical requirements must be examined.\n",
    "\n",
    "Create«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset len: 3004\n",
      "val_dataset len: 751\n",
      "total_dataset len: 3755\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SalaryDataset(data, train=True) \n",
    "test_dataset = SalaryDataset(data, train=False)\n",
    "print('train_dataset len:', len(train_dataset))\n",
    "print('val_dataset len:', len(test_dataset))\n",
    "print('total_dataset len:', len(train_dataset) + len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 178)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.getData().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>salary_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ES</td>\n",
       "      <td>100</td>\n",
       "      <td>ES</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mid-level/Intermediate</td>\n",
       "      <td>Contract</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mid-level/Intermediate</td>\n",
       "      <td>Contract</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year        experience_level employment_type       job_title  \\\n",
       "0       2023     Senior-level/Expert       Full-Time  Data Scientist   \n",
       "1       2023  Mid-level/Intermediate        Contract     ML Engineer   \n",
       "2       2023  Mid-level/Intermediate        Contract     ML Engineer   \n",
       "3       2023     Senior-level/Expert       Full-Time  Data Scientist   \n",
       "4       2023     Senior-level/Expert       Full-Time  Data Scientist   \n",
       "\n",
       "  employee_residence  remote_ratio company_location company_size salary_level  \n",
       "0                 ES           100               ES            L      Level 1  \n",
       "1                 US           100               US            S      Level 1  \n",
       "2                 US           100               US            S      Level 1  \n",
       "3                 CA           100               CA            M      Level 3  \n",
       "4                 CA           100               CA            M      Level 2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8. Apply "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply: Any technical impossibilities for implementation identified must be considered during the technical and methodical provision.\n",
    "\n",
    "It involves technical setup for handling data, which is a crucial part of the methodical provision in machine learning or data processing projects. Ensuring the correct handling and sizing of datasets is vital to the success of such projects, and any technical impossibilities or limitations identified in this area must be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3004, 'test': 751}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataLoader for training and testing datasets \n",
    "dataloaders = {'train': train_dataset, 'test': test_dataset}\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'test']}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for training and testing data is created.\n",
    "This will train 25 epochs, and save the best model during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=1):\n",
    "    since = time.time()\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        # Path to save the best model parameters\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'test']:\n",
    "                # Set model to training mode or evaluation mode\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Training mode\n",
    "                else: \n",
    "                    model.eval()   # Evaluation mode\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs_vector, labels_vector in dataloaders[phase]:\n",
    "\n",
    "                    # Zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs_vector)\n",
    "\n",
    "                        # Predictions and actual results\n",
    "                        pred = torch.argmax(outputs).item()\n",
    "                        result = torch.argmax(labels_vector).item()\n",
    "                        # Calculate loss\n",
    "                        loss = criterion(outputs, labels_vector)\n",
    "\n",
    "                        # Backward pass and optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # Statistics: accumulate loss and count correct predictions\n",
    "                    running_loss += loss.item()\n",
    "                    if pred == result:\n",
    "                        running_corrects += 1\n",
    "\n",
    "                # Learning rate scheduler step in training phase\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                # Calculate loss and accuracy for each epoch\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Time elapsed: {round((time.time() - since))} sec.')\n",
    "                \n",
    "                # Save the model if it has the best accuracy so far\n",
    "                if phase == 'test' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        # Print out total time for training and the best accuracy\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # Load the best model weights before proceeding to the next epoch\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SalaryPredictor, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.output_layer = nn.Linear(32, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in, D_out = 174, 4\n",
    "model = SalaryPredictor(D_in)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9. Provide\n",
    "\n",
    "Provide: The results of the technical and methodical provision form the basis for the professional provision of the prepared analysis results for the target user group. The effects can range from a support of existing processes to a project adjustment to a completely new development (now automated, if applicable) of processes.\n",
    "\n",
    "Technical provision results underpin targeted user analysis with epoch data. And finally save the best prediction result of model, which is easy to deploy and use in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 1.2816 Acc: 0.3692 Time elapsed: 4 sec.\n",
      "test Loss: 1.1817 Acc: 0.4474 Time elapsed: 4 sec.\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.1470 Acc: 0.4534 Time elapsed: 8 sec.\n",
      "test Loss: 1.1508 Acc: 0.4780 Time elapsed: 8 sec.\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.1243 Acc: 0.4640 Time elapsed: 12 sec.\n",
      "test Loss: 1.1442 Acc: 0.4820 Time elapsed: 12 sec.\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.1144 Acc: 0.4707 Time elapsed: 16 sec.\n",
      "test Loss: 1.1387 Acc: 0.4874 Time elapsed: 17 sec.\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.1082 Acc: 0.4734 Time elapsed: 21 sec.\n",
      "test Loss: 1.1383 Acc: 0.4887 Time elapsed: 21 sec.\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.1030 Acc: 0.4824 Time elapsed: 25 sec.\n",
      "test Loss: 1.1316 Acc: 0.4900 Time elapsed: 26 sec.\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.0988 Acc: 0.4820 Time elapsed: 29 sec.\n",
      "test Loss: 1.1288 Acc: 0.4887 Time elapsed: 30 sec.\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.0795 Acc: 0.4887 Time elapsed: 34 sec.\n",
      "test Loss: 1.1088 Acc: 0.4700 Time elapsed: 34 sec.\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 1.0762 Acc: 0.4864 Time elapsed: 38 sec.\n",
      "test Loss: 1.1100 Acc: 0.4714 Time elapsed: 38 sec.\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 1.0749 Acc: 0.4864 Time elapsed: 42 sec.\n",
      "test Loss: 1.1108 Acc: 0.4700 Time elapsed: 42 sec.\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 1.0740 Acc: 0.4893 Time elapsed: 46 sec.\n",
      "test Loss: 1.1115 Acc: 0.4820 Time elapsed: 46 sec.\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 1.0732 Acc: 0.4923 Time elapsed: 50 sec.\n",
      "test Loss: 1.1119 Acc: 0.4834 Time elapsed: 50 sec.\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 1.0725 Acc: 0.4947 Time elapsed: 54 sec.\n",
      "test Loss: 1.1121 Acc: 0.4847 Time elapsed: 54 sec.\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 1.0719 Acc: 0.4947 Time elapsed: 58 sec.\n",
      "test Loss: 1.1123 Acc: 0.4847 Time elapsed: 58 sec.\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 1.0696 Acc: 0.4910 Time elapsed: 62 sec.\n",
      "test Loss: 1.1103 Acc: 0.4847 Time elapsed: 62 sec.\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 1.0689 Acc: 0.4913 Time elapsed: 66 sec.\n",
      "test Loss: 1.1093 Acc: 0.4887 Time elapsed: 66 sec.\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 1.0686 Acc: 0.4877 Time elapsed: 70 sec.\n",
      "test Loss: 1.1089 Acc: 0.4887 Time elapsed: 70 sec.\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 1.0685 Acc: 0.4877 Time elapsed: 74 sec.\n",
      "test Loss: 1.1087 Acc: 0.4887 Time elapsed: 74 sec.\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 1.0684 Acc: 0.4890 Time elapsed: 78 sec.\n",
      "test Loss: 1.1086 Acc: 0.4847 Time elapsed: 78 sec.\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 1.0683 Acc: 0.4890 Time elapsed: 82 sec.\n",
      "test Loss: 1.1086 Acc: 0.4847 Time elapsed: 82 sec.\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 1.0682 Acc: 0.4900 Time elapsed: 86 sec.\n",
      "test Loss: 1.1085 Acc: 0.4847 Time elapsed: 86 sec.\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 1.0677 Acc: 0.4903 Time elapsed: 90 sec.\n",
      "test Loss: 1.1085 Acc: 0.4847 Time elapsed: 90 sec.\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 1.0677 Acc: 0.4903 Time elapsed: 94 sec.\n",
      "test Loss: 1.1084 Acc: 0.4847 Time elapsed: 94 sec.\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 1.0677 Acc: 0.4903 Time elapsed: 98 sec.\n",
      "test Loss: 1.1084 Acc: 0.4847 Time elapsed: 98 sec.\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 1.0677 Acc: 0.4903 Time elapsed: 102 sec.\n",
      "test Loss: 1.1084 Acc: 0.4847 Time elapsed: 102 sec.\n",
      "\n",
      "Training complete in 1m 42s\n",
      "Best val Acc: 0.490013\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, loss_function, optimizer, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk \n",
    "torch.save(model.state_dict(), '../data/model/salary_pred.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the value with the model\n",
    "1. Get all data from the source.\n",
    "2. Add new data to the source.\n",
    "3. Convert the data to datasource for model prediction.\n",
    "4. Get the model and predict the value with the last data in the source. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Get all data from the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 95000. 135000. 175000.]\n",
      "Level 1: < 95000.00 USD\n",
      "Level 2: 95000.00 ~ 135000.00 USD\n",
      "Level 3: 135000.00 ~ 175000.00 USD\n",
      "Level 4: > 175000.00 USD\n",
      "\n",
      "The data of each salary level is balanced.\n",
      "salary_level\n",
      "Level 2    967\n",
      "Level 1    956\n",
      "Level 4    932\n",
      "Level 3    900\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ds_salaries_cleaned.csv')\n",
    "data = convertData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. Add new data to the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>salary_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>2021</td>\n",
       "      <td>Mid-level/Intermediate</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>2020</td>\n",
       "      <td>Entry-level/Junior</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>2020</td>\n",
       "      <td>Entry-level/Junior</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>2021</td>\n",
       "      <td>Senior-level/Expert</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>IN</td>\n",
       "      <td>50</td>\n",
       "      <td>IN</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>2023</td>\n",
       "      <td>Entry-level/Junior</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      work_year        experience_level employment_type             job_title  \\\n",
       "3751       2021  Mid-level/Intermediate       Full-Time        Data Scientist   \n",
       "3752       2020      Entry-level/Junior       Full-Time        Data Scientist   \n",
       "3753       2020      Entry-level/Junior        Contract          Data Analyst   \n",
       "3754       2021     Senior-level/Expert       Full-Time  Data Science Manager   \n",
       "3755       2023      Entry-level/Junior       Full-Time          Data Analyst   \n",
       "\n",
       "     employee_residence  remote_ratio company_location company_size  \\\n",
       "3751                 US           100               US            L   \n",
       "3752                 US           100               US            S   \n",
       "3753                 US           100               US            L   \n",
       "3754                 IN            50               IN            L   \n",
       "3755                 US           100               US            L   \n",
       "\n",
       "     salary_level  \n",
       "3751      Level 3  \n",
       "3752      Level 2  \n",
       "3753      Level 2  \n",
       "3754      Level 1  \n",
       "3755      Level 1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hight_input = {\n",
    "    'work_year': 2023,\n",
    "    'experience_level': 'Senior-level/Expert',\n",
    "    'employment_type': 'Full-Time',\n",
    "    'job_title': 'Data Science Manager',\n",
    "    'employee_residence': ['US'],\n",
    "    'remote_ratio': [100],\n",
    "    'company_location': ['US'],\n",
    "    'company_size': ['L'],\n",
    "    'salary_level': ['Level 1'] # we don't care about the label\n",
    "}\n",
    "\n",
    "low_intput = {\n",
    "    'work_year': 2023,\n",
    "    'experience_level': 'Entry-level/Junior',\n",
    "    'employment_type': 'Full-Time',\n",
    "    'job_title': 'Data Analyst',\n",
    "    'employee_residence': ['US'],\n",
    "    'remote_ratio': [100],\n",
    "    'company_location': ['US'],\n",
    "    'company_size': ['L'],\n",
    "    'salary_level': ['Level 1'] # we don't care about the label\n",
    "}\n",
    "\n",
    "input = low_intput\n",
    "\n",
    "data = pd.concat([data, pd.DataFrame(input)], ignore_index=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. Convert the data to datasource for model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_year              int64\n",
       "experience_level      object\n",
       "employment_type       object\n",
       "job_title             object\n",
       "employee_residence    object\n",
       "remote_ratio           int64\n",
       "company_location      object\n",
       "company_size          object\n",
       "salary_level          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConverter(Dataset):\n",
    "\n",
    "    # Initialization function for loading and preprocessing data\n",
    "    def __init__(self, data, transform=None):\n",
    "        # Create MinMaxScaler and OneHotEncoder for data preprocessing\n",
    "        minmax_scaler = MinMaxScaler()\n",
    "        onehot_enc = OneHotEncoder()\n",
    "\n",
    "        # Split data into categorical features, numerical features, and labels\n",
    "        categorical_features = data[data.select_dtypes(include=['object']).columns].drop('salary_level', axis=1)\n",
    "        categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "        print(f'categorical_features=${categorical_columns}')\n",
    "\n",
    "        numerical_features = data[data.select_dtypes(exclude=['object']).columns]\n",
    "        numerical_columns = data.select_dtypes(exclude=['object']).columns\n",
    "        print(f'numerical_features=${numerical_columns}')\n",
    "        \n",
    "        label_features = data[['salary_level']]\n",
    "\n",
    "        # Normalize numerical features (MinMax normalization)\n",
    "        numerical_features_arr = minmax_scaler.fit_transform(numerical_features)\n",
    "\n",
    "        # Perform one-hot encoding on categorical features\n",
    "        categorical_features_arr = onehot_enc.fit_transform(categorical_features).toarray()\n",
    "\n",
    "        # After one-hot encoding categorical features, retrieve the encoded feature names\n",
    "        label_features = onehot_enc.fit_transform(label_features).toarray()\n",
    "\n",
    "        # Combine normalized numerical features and one-hot encoded categorical features into one dataset\n",
    "        combined_features = pd.DataFrame(data=numerical_features_arr, columns=numerical_features.columns)\n",
    "        combined_features = pd.concat([combined_features, pd.DataFrame(data=categorical_features_arr)], axis=1)\n",
    "        combined_features = pd.concat([combined_features, pd.DataFrame(data=label_features)], axis=1).reset_index(drop=True)\n",
    "\n",
    "        self.data = combined_features\n",
    "\n",
    "    # Returns the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Function for retrieving features and labels for training the neural network\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve the data from the ith row in the self.data DataFrame\n",
    "        sample = self.data.iloc[idx] \n",
    "        # Convert a data structure into a PyTorch tensor and specify the tensor's data type as float\n",
    "        features = torch.FloatTensor(sample[:-4])\n",
    "        label = torch.FloatTensor(sample[-4:])\n",
    "        return features, label\n",
    "\n",
    "    # Returns the entire dataset as a DataFrame\n",
    "    def getData(self):\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_features=$Index(['experience_level', 'employment_type', 'job_title',\n",
      "       'employee_residence', 'company_location', 'company_size',\n",
      "       'salary_level'],\n",
      "      dtype='object')\n",
      "numerical_features=$Index(['work_year', 'remote_ratio'], dtype='object')\n",
      "categorical_features=$Index(['experience_level', 'employment_type', 'job_title',\n",
      "       'employee_residence', 'company_location', 'company_size',\n",
      "       'salary_level'],\n",
      "      dtype='object')\n",
      "numerical_features=$Index(['work_year', 'remote_ratio'], dtype='object')\n",
      "tensor_input = $tensor([1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]), \n",
      "tensor_label = $tensor([1., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "tensor_input = DatasetConverter(data).__getitem__(-1)[0]\n",
    "tensor_label = DatasetConverter(data).__getitem__(-1)[1]\n",
    "print(f'tensor_input = ${tensor_input}, \\ntensor_label = ${tensor_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10. Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request: If the professional provision does not lead to the desired results, changes to the technical and methodical provision can be requested.\n",
    "\n",
    "In this step, we give the mock data to the model and predict the value. If the result is not as expected, we can request changes to the technical and methodical provision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_features=$Index(['experience_level', 'employment_type', 'job_title',\n",
      "       'employee_residence', 'company_location', 'company_size',\n",
      "       'salary_level'],\n",
      "      dtype='object')\n",
      "numerical_features=$Index(['work_year', 'remote_ratio'], dtype='object')\n",
      "output = $tensor([ 1.7652,  0.6796, -0.7465, -2.0051])\n",
      "The predicted salary level is: 0\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "D_in, D_out = 174, 4\n",
    "pred_model = SalaryPredictor(D_in)\n",
    "pred_model.load_state_dict(torch.load('../data/model/salary_pred.pt'))\n",
    "\n",
    "# predict the salary level of the new data\n",
    "with torch.no_grad():\n",
    "    # get the last row of the data\n",
    "    tensor_data = DatasetConverter(data).__getitem__(-1)\n",
    "    input = tensor_data[0]\n",
    "    output = pred_model(input)\n",
    "    print(f'output = ${output}')\n",
    "    pred = torch.argmax(output).item()\n",
    "    print('The predicted salary level is:', pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
